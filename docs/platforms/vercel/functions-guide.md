# Vercel Functions - Gu√≠a Completa para Desarrolladores AWS

> Gu√≠a comparativa para desarrolladores con experiencia en AWS Lambda/Serverless que est√°n aprendiendo Vercel Functions y TypeScript.

## Tabla de Contenidos

1. [Comparaci√≥n AWS Lambda vs Vercel Functions](#comparaci√≥n-aws-lambda-vs-vercel-functions)
2. [Arquitectura de Vercel Functions](#arquitectura-de-vercel-functions)
3. [File-Based Routing](#file-based-routing)
4. [Configuraci√≥n: vercel.json](#configuraci√≥n-verceljson)
5. [Ciclo de Vida](#ciclo-de-vida)
6. [Patrones Comunes en Este Proyecto](#patrones-comunes-en-este-proyecto)
7. [Limitaciones Edge Runtime](#limitaciones-edge-runtime)
8. [Deployment Flow](#deployment-flow)
9. [Pricing Comparison](#pricing-comparison)
10. [Cu√°ndo Usar Cada Runtime](#cu√°ndo-usar-cada-runtime)
11. [Debugging y Logs](#debugging-y-logs)
12. [Cheat Sheet AWS ‚Üí Vercel](#cheat-sheet-aws--vercel)
13. [Recursos y Pr√≥ximos Pasos](#recursos-y-pr√≥ximos-pasos)

---

## Comparaci√≥n AWS Lambda vs Vercel Functions

| Caracter√≠stica | AWS Lambda | Vercel Functions |
|---|---|---|
| **Arquitectura** | Contenedores ef√≠meros en regiones AWS | MicroVMs V8 (Edge) o Node.js containers |
| **Deployment** | Manual/CloudFormation/SAM/Serverless Framework | Git push autom√°tico |
| **Cold Start** | 100-500ms | Edge: <10ms, Node: 50-200ms |
| **Configuraci√≥n** | `serverless.yml` o CloudFormation YAML | Archivos en `app/api/` + `vercel.json` |
| **Rutas** | API Gateway + mappings manuales | File-based routing (autom√°tico) |
| **Runtime** | Python 3.x, Node 20.x, Go, Java, .NET, Ruby | Edge (V8), Node.js, Python, Go, Ruby |
| **Pricing Model** | Requests + GB-seconds | Requests + Active CPU + Memory |
| **Regions** | Selecci√≥n manual de regi√≥n | Edge: Global autom√°tico, Node: iad1 default |
| **Timeout** | 15 min max (Lambda) | Edge: 25s, Node: 10s-300s seg√∫n plan |
| **Concurrency** | 1000 default, configurable | 30K-100K+ autom√°tico |

### Ventajas de Vercel

- ‚úÖ **Zero configuration**: No necesitas configurar API Gateway
- ‚úÖ **Git-based deploys**: Push = deploy autom√°tico
- ‚úÖ **Preview URLs**: Cada PR genera URL √∫nica
- ‚úÖ **Edge global**: Latencia ultra-baja sin configuraci√≥n
- ‚úÖ **Developer Experience**: Logs, analytics, rollbacks integrados

### Ventajas de AWS Lambda

- ‚úÖ **Flexibilidad total**: Cualquier runtime/biblioteca
- ‚úÖ **Timeouts largos**: Hasta 15 minutos
- ‚úÖ **Integraci√≥n AWS**: EventBridge, SQS, DynamoDB, etc.
- ‚úÖ **Control granular**: VPC, roles IAM, layers
- ‚úÖ **Multi-cloud ready**: Terraform, Pulumi support

---

## Arquitectura de Vercel Functions

Vercel ofrece **2 tipos de functions** con casos de uso diferentes:

### 1. Edge Functions ‚ö°

**Runtime**: V8 JavaScript engine (igual que Cloudflare Workers)

**Ejemplo b√°sico**:
```typescript
// app/api/health/route.ts
export const runtime = 'edge'; // ‚Üê Declara Edge Runtime

export async function GET(req: Request): Promise<Response> {
  return new Response(JSON.stringify({ status: 'healthy' }), {
    status: 200,
    headers: { 'content-type': 'application/json' }
  });
}
```

**Caracter√≠sticas**:

| Feature | Valor |
|---|---|
| **Ubicaci√≥n** | Edge m√°s cercano al usuario (global) |
| **Cold Start** | <10ms (pr√°cticamente instant√°neo) |
| **Timeout** | 25s para responder, 300s streaming |
| **Tama√±o c√≥digo** | 1MB (Hobby), 2MB (Pro), 4MB (Enterprise) |
| **Filesystem** | ‚ùå Read-only (no `/tmp`) |
| **Node.js APIs** | ‚ö†Ô∏è Solo subset limitado |
| **Concurrencia** | Alta (30K+ requests simult√°neos) |

**APIs Disponibles**:
- ‚úÖ Web Standard APIs: `fetch`, `Request`, `Response`, `Headers`
- ‚úÖ Crypto Web API
- ‚úÖ Encoding APIs: `TextEncoder`, `TextDecoder`
- ‚úÖ Streams API
- ‚úÖ Subset Node.js: `buffer`, `events`, `util`, `async_hooks`

**Limitaciones**:
- ‚ùå No `fs`, `path`, `child_process`
- ‚ùå No `require()` (solo ES modules)
- ‚ùå No dynamic `import()`
- ‚ùå No native modules (excepto WebAssembly)
- ‚ùå No eval, Function constructor

**Equivalente AWS**: Lambda@Edge + CloudFront Functions

**Casos de uso ideales**:
- Webhooks (WhatsApp, Stripe, etc.)
- Authentication middleware
- Redirects y rewrites
- API proxies
- Health checks
- Rate limiting

---

### 2. Serverless Functions üîß

**Runtime**: Node.js completo (18.x/20.x), Python, Go, Ruby

**Ejemplo b√°sico**:
```typescript
// app/api/process/route.ts
// Sin declarar runtime ‚Üí usa Node.js por defecto

import fs from 'fs';
import { exec } from 'child_process';

export async function POST(req: Request): Promise<Response> {
  // Acceso completo a Node.js APIs
  const tempFile = '/tmp/data.json';
  fs.writeFileSync(tempFile, await req.text());

  // Ejecutar comandos
  exec('convert image.jpg -resize 50% output.jpg');

  return new Response('OK');
}
```

**Caracter√≠sticas**:

| Feature | Valor |
|---|---|
| **Ubicaci√≥n** | Regi√≥n √∫nica (default: `iad1` Washington DC) |
| **Cold Start** | 50-200ms |
| **Timeout** | 10s (Hobby), 60s (Pro), 900s (Enterprise) |
| **Tama√±o c√≥digo** | Sin l√≠mite estricto |
| **Filesystem** | ‚úÖ `/tmp` 500 MB writable |
| **Node.js APIs** | ‚úÖ Todas disponibles |
| **Native modules** | ‚úÖ Soportados |

**APIs Disponibles**:
- ‚úÖ Todas las Node.js APIs est√°ndar
- ‚úÖ Filesystem completo en `/tmp`
- ‚úÖ `child_process` para ejecutar comandos
- ‚úÖ Native modules (sharp, canvas, etc.)
- ‚úÖ Dynamic imports

**Equivalente AWS**: AWS Lambda tradicional

**Casos de uso ideales**:
- Procesamiento de im√°genes/PDFs
- Generaci√≥n de reportes
- Cron jobs complejos
- Operaciones con filesystem
- Bibliotecas con dependencias nativas

---

## File-Based Routing

Una de las mayores diferencias con AWS: **NO necesitas configurar rutas manualmente**.

### En AWS Lambda (Serverless Framework)

```yaml
# serverless.yml
functions:
  webhook:
    handler: handlers/webhook.post
    events:
      - http:
          path: /whatsapp/webhook
          method: POST

  health:
    handler: handlers/health.get
    events:
      - http:
          path: /health
          method: GET
```

### En Vercel (Next.js App Router)

```
app/api/
‚îú‚îÄ‚îÄ health/
‚îÇ   ‚îî‚îÄ‚îÄ route.ts          ‚Üí GET /api/health
‚îú‚îÄ‚îÄ whatsapp/
‚îÇ   ‚îú‚îÄ‚îÄ webhook/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ route.ts      ‚Üí GET/POST /api/whatsapp/webhook
‚îÇ   ‚îî‚îÄ‚îÄ flows/
‚îÇ       ‚îî‚îÄ‚îÄ route.ts      ‚Üí POST /api/whatsapp/flows
‚îî‚îÄ‚îÄ cron/
    ‚îî‚îÄ‚îÄ check-reminders/
        ‚îî‚îÄ‚îÄ route.ts      ‚Üí GET /api/cron/check-reminders
```

**Reglas**:
1. ‚úÖ Archivo **DEBE** llamarse `route.ts` o `route.js`
2. ‚úÖ Exportar funciones HTTP: `GET`, `POST`, `PUT`, `DELETE`, `PATCH`
3. ‚úÖ Firma est√°ndar Web API: `(req: Request) => Promise<Response>`

### Ejemplo Completo

```typescript
// app/api/whatsapp/webhook/route.ts
export const runtime = 'edge';

/**
 * GET - Verificaci√≥n de webhook de WhatsApp
 */
export async function GET(req: Request): Promise<Response> {
  const url = new URL(req.url);
  const mode = url.searchParams.get('hub.mode');
  const token = url.searchParams.get('hub.verify_token');
  const challenge = url.searchParams.get('hub.challenge');

  if (mode === 'subscribe' && token === process.env.VERIFY_TOKEN) {
    return new Response(challenge, { status: 200 });
  }

  return new Response('Forbidden', { status: 403 });
}

/**
 * POST - Recepci√≥n de mensajes de WhatsApp
 */
export async function POST(req: Request): Promise<Response> {
  const payload = await req.json();

  // Procesar mensaje...

  return new Response(JSON.stringify({ success: true }), {
    status: 200,
    headers: { 'content-type': 'application/json' }
  });
}
```

### Rutas Din√°micas

```typescript
// app/api/users/[id]/route.ts
export async function GET(
  req: Request,
  { params }: { params: { id: string } }
): Promise<Response> {
  const userId = params.id; // Extra√≠do autom√°ticamente de la URL

  return new Response(JSON.stringify({ userId }));
}

// GET /api/users/123 ‚Üí params.id = "123"
```

---

## Configuraci√≥n: vercel.json

A diferencia de `serverless.yml`, **NO configuras cada funci√≥n individualmente**.

### Estructura B√°sica

```json
{
  "$schema": "https://openapi.vercel.sh/vercel.json",
  "framework": "nextjs",
  "buildCommand": "next build",

  // Cron jobs (como EventBridge en AWS)
  "crons": [
    {
      "path": "/api/cron/check-reminders",
      "schedule": "0 9 * * *"  // Sintaxis cron est√°ndar (UTC)
    }
  ],

  // Headers globales por ruta
  "headers": [
    {
      "source": "/api/whatsapp/(.*)",
      "headers": [
        {
          "key": "Cache-Control",
          "value": "no-store, no-cache, must-revalidate"
        },
        {
          "key": "X-Content-Type-Options",
          "value": "nosniff"
        }
      ]
    }
  ],

  // Redirects
  "redirects": [
    {
      "source": "/old-path",
      "destination": "/new-path",
      "permanent": true
    }
  ],

  // Rewrites (internal redirects)
  "rewrites": [
    {
      "source": "/api/v1/:path*",
      "destination": "/api/:path*"
    }
  ]
}
```

### ‚ö†Ô∏è IMPORTANTE: NO configurar runtime aqu√≠

```json
‚ùå INCORRECTO:
{
  "functions": {
    "app/api/health/route.ts": {
      "runtime": "edge"  // NO hacer esto
    }
  }
}

‚úÖ CORRECTO:
// app/api/health/route.ts
export const runtime = 'edge'; // Declarar en el archivo
```

### Configuraci√≥n de Regiones (Serverless Functions)

```json
{
  "regions": ["iad1", "sfo1"]  // Multi-region deployment
}
```

Para Edge Functions, la regi√≥n es autom√°tica (global).

---

## Ciclo de Vida

### AWS Lambda
```
Request ‚Üí API Gateway ‚Üí Cold Start (si idle) ‚Üí Lambda Container ‚Üí Handler ‚Üí Response
          ‚Üì
     CloudWatch Logs
```

**Cold Start triggers**:
- Primera invocaci√≥n
- Sin requests por >10-15 min
- Deploy nuevo
- Escalado (nueva instancia)

### Vercel Edge Functions
```
Request ‚Üí Edge CDN (m√°s cercano) ‚Üí Micro Cold Start (<10ms) ‚Üí V8 Isolate ‚Üí Handler ‚Üí Response
          ‚Üì
     Vercel Logs
```

**Cold Start triggers**:
- Primera invocaci√≥n en ese edge
- Sin requests por >30 min
- Deploy nuevo

### Vercel Serverless Functions
```
Request ‚Üí Vercel CDN ‚Üí Regi√≥n (iad1) ‚Üí Cold Start (si idle) ‚Üí Node Container ‚Üí Handler ‚Üí Response
          ‚Üì
     Vercel Logs
```

**Optimizaci√≥n "Fluid Compute"**:
- Vercel mantiene containers warm m√°s tiempo que Lambda
- Escalado adaptativo seg√∫n patrones de tr√°fico
- Reducci√≥n de cold starts del 40-60%

---

## Patrones Comunes en Este Proyecto

### 1. Fire-and-Forget con `waitUntil()`

**Problema**: WhatsApp requiere respuesta en <5 segundos, pero el procesamiento puede tomar 10-30 segundos.

**Soluci√≥n AWS (SQS + Lambda)**:
```python
# Lambda webhook handler
import boto3
sqs = boto3.client('sqs')

def webhook_handler(event, context):
    # Validar webhook
    message = validate(event)

    # Enviar a SQS (async)
    sqs.send_message(
        QueueUrl=os.environ['QUEUE_URL'],
        MessageBody=json.dumps(message)
    )

    return {'statusCode': 200, 'body': '{"success": true}'}

# Lambda processor (trigger: SQS)
def process_handler(event, context):
    for record in event['Records']:
        message = json.loads(record['body'])
        process_with_ai(message)  # Toma 20s
```

**Soluci√≥n Vercel (waitUntil)**:
```typescript
// app/api/whatsapp/webhook/route.ts
import { waitUntil } from '@vercel/functions';

export const runtime = 'edge';

export async function POST(req: Request): Promise<Response> {
  // FAST PATH: Validaciones r√°pidas (<100ms)
  const rawBody = await req.text();
  const isValid = await validateSignature(req, rawBody);

  if (!isValid) {
    return new Response('Unauthorized', { status: 401 });
  }

  const message = JSON.parse(rawBody);

  // ‚úÖ RESPONDER INMEDIATAMENTE (<100ms)
  // Fire-and-forget: Procesar en background
  waitUntil(
    processInBackground(message).catch(handleError)
  );

  return new Response(JSON.stringify({ success: true }), {
    status: 200,
    headers: { 'content-type': 'application/json' }
  });
}

/**
 * Esta funci√≥n se ejecuta en background SIN bloquear la respuesta
 * Puede tomar hasta 25s (Edge) o 60s (Node.js)
 */
async function processInBackground(msg: any): Promise<void> {
  try {
    // Persistir en DB (con deduplicaci√≥n)
    const result = await persistMessage(msg);

    if (result.isDuplicate) {
      return; // Ya procesado
    }

    // Procesar con AI (10-20s)
    await sendToAI(msg.content);

    // Enviar respuesta a WhatsApp
    await sendWhatsAppMessage(msg.from, response);

  } catch (error) {
    logger.error('Background processing failed', error);
    // Enviar mensaje de error al usuario
    await sendWhatsAppMessage(msg.from, 'Disculpa, hubo un error');
  }
}
```

**Diferencias clave**:
- AWS: 2 Lambdas + SQS (mayor complejidad)
- Vercel: 1 funci√≥n + `waitUntil()` (m√°s simple)
- AWS: Retry autom√°tico (SQS DLQ)
- Vercel: Manejo de errores manual

**C√≥digo real del proyecto**: `app/api/whatsapp/webhook/route.ts:189-196`

---

### 2. Cron Jobs

**AWS (EventBridge)**:
```yaml
# serverless.yml
functions:
  checkReminders:
    handler: handlers/cron.check
    events:
      - schedule:
          rate: cron(0 9 * * ? *)  # 9 AM UTC diario
          enabled: true
```

```python
# handlers/cron.py
def check(event, context):
    reminders = get_due_reminders()
    for r in reminders:
        send_whatsapp(r.phone, r.message)
    return {'statusCode': 200}
```

**Vercel**:
```json
// vercel.json
{
  "crons": [
    {
      "path": "/api/cron/check-reminders",
      "schedule": "0 9 * * *"  // 9 AM UTC diario
    }
  ]
}
```

```typescript
// app/api/cron/check-reminders/route.ts
export const runtime = 'edge';

export async function GET(req: Request): Promise<Response> {
  // ‚úÖ Verificar autenticaci√≥n (Vercel agrega header autom√°tico)
  const authHeader = req.headers.get('authorization');
  const cronSecret = process.env.CRON_SECRET;

  if (cronSecret && authHeader !== `Bearer ${cronSecret}`) {
    return new Response('Unauthorized', { status: 401 });
  }

  // Obtener recordatorios pendientes
  const reminders = await getDueReminders();

  // Procesar cada uno
  const results = [];
  for (const r of reminders) {
    try {
      await sendWhatsAppText(r.phone, r.message);
      await markReminderAsSent(r.id);
      results.push({ id: r.id, status: 'sent' });
    } catch (err) {
      results.push({ id: r.id, status: 'failed', error: err.message });
    }
  }

  return new Response(JSON.stringify({ processed: results.length, results }), {
    headers: { 'content-type': 'application/json' }
  });
}
```

**Diferencias**:
- AWS: EventBridge + Lambda (separados)
- Vercel: `vercel.json` + endpoint (integrado)
- AWS: CloudWatch Events para monitoreo
- Vercel: Logs en dashboard + alertas integradas

**C√≥digo real del proyecto**: `app/api/cron/check-reminders/route.ts`

---

### 3. Environment Variables

**AWS (SSM Parameter Store)**:
```bash
# Configurar
aws ssm put-parameter \
  --name /myapp/prod/WHATSAPP_TOKEN \
  --value "xxx" \
  --type SecureString

# serverless.yml
provider:
  environment:
    WHATSAPP_TOKEN: ${ssm:/myapp/prod/WHATSAPP_TOKEN}
```

```python
# Acceder
import os
token = os.environ['WHATSAPP_TOKEN']
```

**Vercel**:
```bash
# Configurar via CLI
vercel env add WHATSAPP_TOKEN

# O via Dashboard: Settings ‚Üí Environment Variables

# Desarrollo local (.env.local)
WHATSAPP_TOKEN=xxx
SUPABASE_URL=https://xxx.supabase.co
```

```typescript
// Acceso directo (‚ö†Ô∏è no type-safe)
const token = process.env.WHATSAPP_TOKEN;

// ‚úÖ MEJOR: Helper con validaci√≥n
// lib/env.ts
import { z } from 'zod';

const envSchema = z.object({
  WHATSAPP_TOKEN: z.string().min(1),
  WHATSAPP_PHONE_ID: z.string().min(1),
  SUPABASE_URL: z.string().url(),
  SUPABASE_KEY: z.string().min(1),
  OPENAI_API_KEY: z.string().min(1),
});

export function getEnv() {
  const parsed = envSchema.safeParse(process.env);

  if (!parsed.success) {
    throw new Error(`Invalid env: ${parsed.error.message}`);
  }

  return parsed.data;
}

// Uso en functions
import { getEnv } from '@/lib/env';

export async function POST(req: Request) {
  const env = getEnv(); // Type-safe + validated
  const token = env.WHATSAPP_TOKEN;
  // ...
}
```

**Scopes de variables**:
- **Production**: Solo en deploys de `main` branch
- **Preview**: Solo en PRs y feature branches
- **Development**: Solo en `vercel dev`

---

### 4. Streaming Responses

**Use case**: Generar respuestas largas con AI sin timeout.

```typescript
// app/api/stream/route.ts
export const runtime = 'edge';

export async function POST(req: Request): Promise<Response> {
  const { prompt } = await req.json();

  // Stream de OpenAI/Anthropic
  const stream = await openai.chat.completions.create({
    model: 'gpt-4',
    messages: [{ role: 'user', content: prompt }],
    stream: true,
  });

  // Convertir a ReadableStream
  const encoder = new TextEncoder();
  const readableStream = new ReadableStream({
    async start(controller) {
      for await (const chunk of stream) {
        const text = chunk.choices[0]?.delta?.content || '';
        controller.enqueue(encoder.encode(text));
      }
      controller.close();
    },
  });

  return new Response(readableStream, {
    headers: {
      'content-type': 'text/plain',
      'transfer-encoding': 'chunked',
    },
  });
}
```

**L√≠mites**:
- Edge: 300 segundos streaming
- Node.js: Seg√∫n timeout configurado

---

## Limitaciones Edge Runtime

**Comparaci√≥n detallada**:

| Feature | Edge Runtime | Node.js Runtime | AWS Lambda |
|---|---|---|---|
| **File System** | ‚ùå No | ‚úÖ `/tmp` 500MB | ‚úÖ `/tmp` 512MB-10GB |
| **Native Modules** | ‚ùå Solo WASM | ‚úÖ S√≠ | ‚úÖ S√≠ (+ Layers) |
| **Dynamic `import()`** | ‚ùå No | ‚úÖ S√≠ | ‚úÖ S√≠ |
| **`require()`** | ‚ùå No | ‚úÖ S√≠ | ‚úÖ S√≠ |
| **`child_process`** | ‚ùå No | ‚úÖ S√≠ | ‚úÖ S√≠ |
| **`fs`, `path`, `os`** | ‚ùå No | ‚úÖ S√≠ | ‚úÖ S√≠ |
| **Crypto (Web API)** | ‚úÖ S√≠ | ‚úÖ S√≠ | ‚úÖ S√≠ |
| **fetch API** | ‚úÖ S√≠ | ‚úÖ S√≠ | ‚ö†Ô∏è Requiere polyfill (Node <18) |
| **Streaming** | ‚úÖ 300s | ‚úÖ Seg√∫n timeout | ‚úÖ Seg√∫n timeout |
| **Buffer** | ‚úÖ S√≠ | ‚úÖ S√≠ | ‚úÖ S√≠ |
| **WebSocket** | ‚ö†Ô∏è Limitado | ‚úÖ S√≠ | ‚úÖ S√≠ + API Gateway |
| **Timers** | ‚úÖ S√≠ | ‚úÖ S√≠ | ‚úÖ S√≠ |

### Bibliotecas Comunes

| Biblioteca | Edge | Node.js | Notas |
|---|---|---|---|
| `@anthropic-ai/sdk` | ‚úÖ | ‚úÖ | Messages API compatible |
| `@anthropic-ai/claude-agent-sdk` | ‚ùå | ‚úÖ | Requiere `fs` |
| `openai` | ‚úÖ | ‚úÖ | Compatible desde v4+ |
| `groq-sdk` | ‚úÖ | ‚úÖ | Audio transcription |
| `tesseract.js` | ‚úÖ | ‚úÖ | OCR compatible |
| `sharp` | ‚ùå | ‚úÖ | Requiere native bindings |
| `canvas` | ‚ùå | ‚úÖ | Native module |
| `pdf-lib` | ‚úÖ | ‚úÖ | Pure JS |
| `prisma` | ‚ö†Ô∏è | ‚úÖ | Edge solo con Data Proxy |
| `bcrypt` | ‚ùå | ‚úÖ | Use `bcryptjs` para Edge |
| `jsonwebtoken` | ‚úÖ | ‚úÖ | Compatible |
| `zod` | ‚úÖ | ‚úÖ | Schema validation |

### Verificar Compatibilidad

```typescript
// Detectar runtime
if (typeof EdgeRuntime !== 'string') {
  // Estamos en Node.js
  const fs = require('fs');
} else {
  // Estamos en Edge
  console.log('Running on Edge');
}

// O usar conditional exports en package.json
{
  "exports": {
    "edge-light": "./dist/edge.js",
    "node": "./dist/node.js",
    "default": "./dist/edge.js"
  }
}
```

---

## Deployment Flow

### AWS Lambda (Serverless Framework)

```bash
# 1. Instalar dependencias
npm install

# 2. Compilar TypeScript (si aplica)
npm run build

# 3. Empaquetar (crear .zip)
serverless package

# 4. Deploy
serverless deploy --stage prod --region us-east-1

# Output:
# ‚úì Service deployed
# endpoints:
#   POST - https://xxx.execute-api.us-east-1.amazonaws.com/prod/webhook
# functions:
#   webhook: myapp-prod-webhook
```

**Tiempo**: 1-3 minutos

---

### Vercel

```bash
# 1. Configurar proyecto (primera vez)
vercel

# 2. Link a Git (si no est√°)
vercel git connect

# 3. Deploy (autom√°tico en cada push)
git add .
git commit -m "feat: add new endpoint"
git push origin main

# ‚úÖ Deploy autom√°tico inicia
# Output en GitHub PR:
#   üî® Building...
#   ‚úì Preview: https://myapp-abc123.vercel.app
#   ‚úì Production: https://myapp.vercel.app (si es main)
```

**Tiempo**: 30-60 segundos

---

### Comparaci√≥n de Workflows

| Aspecto | AWS Lambda | Vercel |
|---|---|---|
| **Setup inicial** | AWS CLI, IAM, Serverless Framework | `vercel` CLI o Git connect |
| **Deploy** | `sls deploy` manual | Git push autom√°tico |
| **Rollback** | `sls deploy --stage prod` anterior | UI: Rollback en 1 click |
| **Environments** | Stages (dev/prod) manual | Branch-based autom√°tico |
| **Preview** | Manual (deploy a stage diferente) | Autom√°tico por PR |
| **Secrets** | SSM/Secrets Manager | Vercel Dashboard |
| **CI/CD** | GitHub Actions + AWS credentials | Integrado (cero config) |

---

### Preview URLs (Feature √önico de Vercel)

Cada PR genera una URL √∫nica:

```
PR #42: feat/new-feature
‚Üì
Deploy autom√°tico
‚Üì
https://myapp-git-feat-new-feature-user.vercel.app
```

**Ventajas**:
- ‚úÖ Testing sin afectar producci√≥n
- ‚úÖ Compartir con stakeholders
- ‚úÖ Testing de integraci√≥n antes de merge
- ‚úÖ URL estable durante vida del PR

---

## Pricing Comparison

### AWS Lambda (us-east-1)

**Compute**:
- Primeros 400,000 GB-seconds/mes: GRATIS
- Despu√©s: $0.0000166667 por GB-second

**Requests**:
- Primer 1M requests/mes: GRATIS
- Despu√©s: $0.20 por 1M requests

**API Gateway**:
- $1.00 per 1M requests

**Ejemplo (500K requests, 1GB RAM, 3s avg)**:
- Requests: GRATIS (< 1M)
- Compute: 500K * 1GB * 3s = 1.5M GB-s = GRATIS (< 400K GB-s)
- API Gateway: $0.50
- **Total: ~$0.50/mes**

---

### Vercel

**Hobby Plan** (GRATIS):
- 100 GB-hours/mes
- 100K invocations/mes
- 1K build minutes
- Edge & Serverless incluidos

**Pro Plan** ($20/mes):
- 1000 GB-hours incluidos
- 100K invocations incluidos
- Despu√©s:
  - $0.60 por 1M invocations
  - $40 por 100 GB-hours adicionales

**Ejemplo (500K requests, 3s avg)**:
- Invocations: 500K - 100K = 400K exceso
- Costo invocations: 400K * $0.60/1M = $0.24
- GB-hours: 500K * 3s * 1GB / 3600 = ~417 GB-hours
- GB-hours exceso: 417 - 1000 = GRATIS (dentro de plan)
- **Total: $20 (plan) + $0.24 = $20.24/mes**

---

### Comparaci√≥n Real (Este Proyecto)

**Carga**:
- 2,000 mensajes/d√≠a = 60K/mes
- Promedio 2s por request
- 1 GB RAM

| Provider | Costo Mensual | Notas |
|---|---|---|
| **AWS Lambda** | ~$5 | Solo Lambda + API Gateway |
| **Vercel Hobby** | $0 | Dentro de l√≠mites gratis |
| **Vercel Pro** | $20 | Extras: Analytics, Teams, Support |

**Conclusi√≥n**:
- Para proyectos peque√±os (<100K req/mes): Vercel Hobby GRATIS
- Para startups (100K-1M req/mes): Similar o m√°s barato
- Para empresas (>10M req/mes): AWS Lambda m√°s econ√≥mico

---

## Cu√°ndo Usar Cada Runtime

### Usa Edge Functions ‚ö° cuando:

‚úÖ **Latencia es cr√≠tica**
- API endpoints p√∫blicos
- Webhooks (WhatsApp, Stripe, GitHub)
- Authentication middleware

‚úÖ **Requests peque√±os y r√°pidos**
- Health checks
- Redirects/Rewrites
- Rate limiting
- Feature flags

‚úÖ **Cobertura global**
- API internacional
- CDN personalizado
- Geo-routing

‚úÖ **Solo necesitas Web APIs**
- HTTP requests
- JSON parsing
- Crypto operations

**Ejemplos en este proyecto**:
- `app/api/whatsapp/webhook/route.ts` - Webhook WhatsApp
- `app/api/health/route.ts` - Health check
- `app/api/cron/check-reminders/route.ts` - Cron jobs

---

### Usa Serverless Functions üîß cuando:

‚úÖ **Necesitas Node.js APIs completas**
- Filesystem operations
- Child processes
- Native modules

‚úÖ **Procesamiento pesado**
- Image processing (sharp, canvas)
- PDF generation
- Video transcoding
- Data transformations

‚úÖ **Dependencias nativas**
- Bibliotecas con C/C++ bindings
- Puppeteer/Playwright
- Prisma (sin Data Proxy)

‚úÖ **Timeouts largos (>25s)**
- Batch processing
- Report generation
- ML inference

**Cu√°ndo migrar de Edge ‚Üí Serverless**:

```typescript
// ‚ùå NO funciona en Edge
export const runtime = 'edge';
import sharp from 'sharp'; // Error: native module

// ‚úÖ Cambia a Node.js
// Remover la l√≠nea runtime = 'edge'
import sharp from 'sharp'; // ‚úì Funciona
```

---

### ‚ö†Ô∏è Aclaraci√≥n Importante: Procesamiento LOCAL vs V√çA API

**Confusi√≥n com√∫n**: La tabla abajo dice "Transcripci√≥n audio ‚ùå Edge", pero el proyecto `migue.ai` S√ç procesa audio en Edge Functions. ¬øContradicci√≥n?

**Respuesta**: NO. La diferencia clave es **C√ìMO** procesas:

#### Procesamiento LOCAL (NO funciona en Edge)

```typescript
// ‚ùå NO FUNCIONA en Edge Runtime
export const runtime = 'edge';

import sharp from 'sharp';           // ‚ùå Native module (C++)
import { exec } from 'child_process'; // ‚ùå No child_process
import fs from 'fs';                 // ‚ùå No filesystem

// Intentar procesar audio localmente
const audioBuffer = await req.arrayBuffer();
exec('ffmpeg -i audio.mp3 output.wav'); // ‚ùå FALLA
```

**Raz√≥n**: Edge Runtime NO tiene acceso a:
- Native modules (C/C++ bindings)
- Filesystem (`fs`, `/tmp`)
- Child processes (`exec`, `spawn`)

---

#### Procesamiento V√çA API (S√ç funciona en Edge)

```typescript
// ‚úÖ FUNCIONA PERFECTAMENTE en Edge Runtime
export const runtime = 'edge';

import Groq from 'groq-sdk';        // ‚úÖ Pure JS SDK
import Tesseract from 'tesseract.js'; // ‚úÖ WebAssembly (WASM)

// Procesar audio v√≠a Groq API
const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });
const audioUrl = 'https://whatsapp.com/audio.mp3';

const transcription = await groq.audio.transcriptions.create({
  file: audioUrl,  // ‚úÖ Groq procesa remotamente
  model: 'whisper-large-v3',
});

console.log(transcription.text); // ‚úÖ FUNCIONA
```

**Raz√≥n**: Solo usas:
- `fetch` API (est√°ndar web)
- SDKs pure JavaScript
- APIs externas (Groq, Anthropic, etc.)

---

#### Tabla Comparativa: ¬øQu√© M√©todo Usar?

| Tarea | M√©todo LOCAL | M√©todo V√çA API | Edge Compatible | Usado en migue.ai |
|---|---|---|---|---|
| **Audio ‚Üí Texto** | FFmpeg + Whisper local | Groq Whisper API | ‚úÖ **S√≠ (v√≠a API)** | ‚úÖ Groq API |
| **Im√°genes ‚Üí Texto (OCR)** | Tesseract native | Tesseract.js (WASM) | ‚úÖ **S√≠ (WASM)** | ‚úÖ Tesseract.js |
| **PDF ‚Üí Texto** | pdf-lib + native deps | Claude Vision API | ‚úÖ **S√≠ (v√≠a API)** | ‚úÖ Claude Vision |
| **Resize im√°genes** | sharp (native) | Cloudinary API | ‚ùå **No local** | N/A |
| **Generar PDFs** | Puppeteer (native) | HTML ‚Üí PDF API | ‚ùå **No local** | N/A |
| **Video processing** | FFmpeg (native) | Mux API | ‚ùå **No local** | N/A |

---

#### Ejemplos Reales del Proyecto

**1. Procesamiento Audio en Edge** (`lib/ai-processing-v2.ts`):
```typescript
export const runtime = 'edge';

export async function processAudioMessage(
  conversationId: string,
  userId: string,
  message: NormalizedMessage
): Promise<void> {
  const provider = getProviderManager();
  const groq = provider.getGroq(); // ‚úÖ Groq SDK (pure JS)

  // Descargar audio de WhatsApp
  const audioBuffer = await downloadMedia(message.mediaUrl);

  // ‚úÖ Transcribir v√≠a Groq API (NO localmente)
  const transcription = await groq.audio.transcriptions.create({
    file: new File([audioBuffer], 'audio.mp3'),
    model: 'whisper-large-v3-turbo',
  });

  // Procesar con AI
  await processMessageWithAI(conversationId, userId, from, transcription.text);
}
```

**2. OCR de Im√°genes en Edge** (`lib/tesseract-ocr.ts`):
```typescript
export const runtime = 'edge';

import Tesseract from 'tesseract.js';

export async function extractTextFromImage(imageUrl: string): Promise<string> {
  // ‚úÖ Tesseract.js usa WebAssembly (Edge compatible)
  const { data: { text } } = await Tesseract.recognize(imageUrl, 'eng+spa', {
    logger: (m) => console.log(m),
  });

  return text;
}
```

**3. An√°lisis de PDFs en Edge** (`lib/ai-processing-v2.ts`):
```typescript
export const runtime = 'edge';

export async function processDocumentMessage(
  conversationId: string,
  userId: string,
  message: NormalizedMessage
): Promise<void> {
  // Opci√≥n 1: Enviar PDF a Claude Vision API
  const claude = provider.getClaude();
  const response = await claude.messages.create({
    model: 'claude-sonnet-4-5',
    messages: [{
      role: 'user',
      content: [
        { type: 'document', source: { url: message.mediaUrl } },
        { type: 'text', text: 'Resume este documento' },
      ],
    }],
  });

  // ‚úÖ Claude procesa el PDF remotamente, no localmente
}
```

---

### Matriz de Decisi√≥n (Actualizada)

**Leyenda**:
- ‚úÖ = Funciona bien
- ‚ö†Ô∏è = Funciona pero con limitaciones
- ‚ùå = NO funciona o requiere Serverless
- üîß = Requiere procesamiento LOCAL (Serverless only)
- üåê = Funciona v√≠a API externa (Edge OK)

| Use Case | Edge | Serverless | M√©todo | Raz√≥n |
|---|---|---|---|---|
| **Webhook WhatsApp** | ‚úÖ | ‚ö†Ô∏è | Web APIs | Latencia baja, requests simples |
| **Transcripci√≥n audio** üåê | ‚úÖ | ‚úÖ | **Groq API** | ‚úÖ Edge si usas API (Groq, OpenAI Whisper) |
| **Transcripci√≥n audio** üîß | ‚ùå | ‚úÖ | FFmpeg local | ‚ùå Edge NO si usas bibliotecas nativas |
| **Health check** | ‚úÖ | ‚úÖ | Fetch | Ambos funcionan, Edge m√°s r√°pido |
| **OCR im√°genes** üåê | ‚úÖ | ‚úÖ | **Tesseract.js** | ‚úÖ Edge con Tesseract.js (WASM) o Claude Vision |
| **Procesamiento im√°genes** üîß | ‚ùå | ‚úÖ | sharp (native) | ‚ùå Edge NO si necesitas resize/crop local (sharp) |
| **An√°lisis PDF** üåê | ‚úÖ | ‚úÖ | **Claude Vision** | ‚úÖ Edge v√≠a Claude Vision API |
| **Generaci√≥n PDF** üîß | ‚ùå | ‚úÖ | Puppeteer | ‚ùå Edge NO (canvas/puppeteer son nativos) |
| **Rate limiting** | ‚úÖ | ‚ö†Ô∏è | Memory/Redis | Edge m√°s r√°pido globalmente |
| **Database queries** | ‚úÖ | ‚úÖ | Supabase | Ambos OK, Edge si <25s |
| **Cron jobs** | ‚úÖ | ‚úÖ | Scheduled | Edge para tareas simples |
| **File uploads** | ‚ö†Ô∏è | ‚úÖ | FormData | Edge limitado a 4.5MB body |
| **Streaming AI** | ‚úÖ | ‚úÖ | ReadableStream | Edge ideal para streaming (300s) |

---

#### Conclusi√≥n: ¬øEdge o Serverless?

**Usa Edge Functions para**:
- ‚úÖ Audio ‚Üí Texto v√≠a **Groq/OpenAI API**
- ‚úÖ Imagen ‚Üí Texto v√≠a **Tesseract.js (WASM)** o **Claude Vision**
- ‚úÖ PDF ‚Üí An√°lisis v√≠a **Claude Vision API**
- ‚úÖ Cualquier procesamiento que use **APIs externas**

**Usa Serverless Functions para**:
- üîß Procesamiento LOCAL con bibliotecas nativas (sharp, FFmpeg)
- üîß Generaci√≥n de PDFs/im√°genes desde cero (Puppeteer, canvas)
- üîß Video processing local
- üîß Cualquier tarea que requiera filesystem o child processes

---

## Debugging y Logs

### AWS Lambda (CloudWatch)

```python
import logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

def handler(event, context):
    logger.info('Processing request', extra={
        'user_id': event.get('userId'),
        'request_id': context.request_id
    })

    try:
        result = process()
        return {'statusCode': 200, 'body': result}
    except Exception as e:
        logger.error('Error processing', exc_info=True)
        return {'statusCode': 500, 'body': str(e)}
```

**Ver logs**:
```bash
aws logs tail /aws/lambda/myapp-prod-webhook --follow
```

---

### Vercel

```typescript
// Logs autom√°ticos en Vercel Dashboard
export async function POST(req: Request): Promise<Response> {
  console.log('Processing request', {
    url: req.url,
    method: req.method
  });

  try {
    const result = await process();
    return new Response(JSON.stringify(result));
  } catch (error) {
    console.error('Error processing:', error);
    return new Response('Error', { status: 500 });
  }
}
```

**Ver logs**:
```bash
# CLI
vercel logs [deployment-url] --follow

# O en Dashboard: Deployments ‚Üí [tu deploy] ‚Üí Function Logs
```

---

### Logger Customizado (Recomendado)

```typescript
// lib/logger.ts
type LogLevel = 'debug' | 'info' | 'warn' | 'error';

interface LogContext {
  requestId?: string;
  userId?: string;
  conversationId?: string;
  metadata?: Record<string, any>;
}

class Logger {
  private log(level: LogLevel, message: string, context?: LogContext) {
    const timestamp = new Date().toISOString();
    const logEntry = {
      timestamp,
      level,
      message,
      ...context,
    };

    console.log(JSON.stringify(logEntry));
  }

  debug(message: string, context?: LogContext) {
    if (process.env.NODE_ENV === 'production') return;
    this.log('debug', message, context);
  }

  info(message: string, context?: LogContext) {
    this.log('info', message, context);
  }

  warn(message: string, context?: LogContext) {
    this.log('warn', message, context);
  }

  error(message: string, error: Error, context?: LogContext) {
    this.log('error', message, {
      ...context,
      error: {
        message: error.message,
        stack: error.stack,
        name: error.name,
      },
    });
  }
}

export const logger = new Logger();

// Uso
import { logger } from '@/lib/logger';

export async function POST(req: Request) {
  const requestId = crypto.randomUUID();

  logger.info('Webhook received', { requestId });

  try {
    await process();
  } catch (error) {
    logger.error('Processing failed', error, { requestId });
  }
}
```

**Ver logs estructurados**:
```bash
# Filtrar por error
vercel logs --filter='level="error"'

# Filtrar por requestId
vercel logs --filter='requestId="abc-123"'
```

---

### Monitoreo y Alertas

**Vercel Pro incluye**:
- Real-time logs streaming
- Error tracking
- Performance metrics
- Alerts (Slack, email, webhook)

```json
// vercel.json
{
  "monitoring": {
    "alerts": [
      {
        "type": "function-error-rate",
        "threshold": 0.05,  // 5% error rate
        "period": "5m",
        "integrations": ["slack"]
      }
    ]
  }
}
```

---

## Cheat Sheet AWS ‚Üí Vercel

### Conceptos Equivalentes

| AWS | Vercel | Notas |
|---|---|---|
| `handler.py` | `route.ts` | Archivo de funci√≥n |
| `def handler(event, context)` | `export async function POST(req: Request)` | Firma |
| `serverless.yml` | `vercel.json` | Config (limitado) |
| `sls deploy` | `git push` | Deployment |
| Lambda@Edge | Edge Functions | Edge compute |
| Lambda (Node.js) | Serverless Functions | Compute tradicional |
| API Gateway | File-based routing | Rutas autom√°ticas |
| EventBridge | Cron (`vercel.json`) | Scheduled tasks |
| SQS | `waitUntil()` | Background processing |
| CloudWatch | Vercel Logs | Logging |
| IAM Roles | Environment Variables | Secrets |
| VPC | - | No equivalente |
| Layers | `node_modules` | Shared code |
| DLQ | Manual retry logic | Error handling |
| Provisioned Concurrency | Always warm (Fluid) | Reduce cold starts |

---

### Comandos Comunes

| Tarea | AWS (Serverless) | Vercel |
|---|---|---|
| **Deploy producci√≥n** | `sls deploy --stage prod` | `git push origin main` |
| **Deploy preview** | `sls deploy --stage dev` | `git push origin feature-x` |
| **Ver logs** | `sls logs -f webhook` | `vercel logs` |
| **Rollback** | `sls deploy --stage prod` (versi√≥n anterior) | UI: Rollback button |
| **Env vars** | `sls deploy` (actualiza stack) | `vercel env add VAR` |
| **Invoke local** | `sls invoke local -f webhook` | `vercel dev` |
| **Ver endpoints** | `sls info` | `vercel inspect` |

---

### Migraci√≥n Checklist

- [ ] **Convertir handlers a route.ts**
  - `handler.py` ‚Üí `app/api/[name]/route.ts`
  - `def handler` ‚Üí `export async function POST`

- [ ] **Actualizar responses**
  - `{'statusCode': 200}` ‚Üí `new Response('OK', { status: 200 })`

- [ ] **Reemplazar AWS SDKs**
  - `boto3` (S3) ‚Üí `@vercel/blob`
  - `boto3` (DynamoDB) ‚Üí Supabase/Postgres
  - `boto3` (SES) ‚Üí Resend/SendGrid

- [ ] **Adaptar background processing**
  - SQS ‚Üí `waitUntil()`

- [ ] **Migrar cron jobs**
  - EventBridge ‚Üí `vercel.json` crons

- [ ] **Environment variables**
  - SSM ‚Üí Vercel Dashboard

- [ ] **Logging**
  - CloudWatch ‚Üí Vercel Logs + logger

- [ ] **Testing**
  - `pytest` ‚Üí Jest + Vitest

- [ ] **CI/CD**
  - GitHub Actions + AWS credentials ‚Üí Git push (autom√°tico)

---

## Recursos y Pr√≥ximos Pasos

### Documentaci√≥n Oficial

- [Vercel Functions](https://vercel.com/docs/functions)
- [Edge Runtime API](https://vercel.com/docs/functions/edge-functions/edge-runtime)
- [Serverless Functions](https://vercel.com/docs/functions/serverless-functions)
- [Next.js App Router](https://nextjs.org/docs/app)
- [Vercel CLI](https://vercel.com/docs/cli)

### Gu√≠as de Migraci√≥n

- [AWS Lambda ‚Üí Vercel](https://vercel.com/guides/migrate-to-vercel-from-aws-lambda)
- [Python ‚Üí TypeScript](https://github.com/microsoft/TypeScript-Website/blob/v2/packages/documentation/copy/en/tutorials/TypeScript%20for%20Python%20Devs.md)
- [Serverless Framework ‚Üí Vercel](https://vercel.com/guides/migrate-from-serverless-framework)

### Learning Path para Devs AWS

1. **Fundamentos TypeScript** (si vienes de Python)
   - [TypeScript for Python Developers](https://www.typescriptlang.org/docs/handbook/typescript-from-scratch.html)
   - Tipos, interfaces, generics

2. **Next.js App Router** (equivalente a API Gateway)
   - File-based routing
   - Middleware
   - API routes

3. **Edge Runtime** (equivalente a Lambda@Edge)
   - Web Standard APIs
   - Limitaciones y workarounds

4. **Vercel Platform**
   - Deployments y previews
   - Environment variables
   - Monitoring y logs

### Proyectos de Pr√°ctica

1. **Webhook Processor** (este proyecto)
   - WhatsApp webhook
   - Fire-and-forget con `waitUntil()`
   - Edge Functions

2. **Cron Job**
   - Daily reminders
   - Database queries
   - Email notifications

3. **API Proxy**
   - Rate limiting
   - Caching
   - Authentication

4. **Image Processing** (Serverless Functions)
   - sharp para resize
   - Upload a Vercel Blob
   - Streaming responses

### Herramientas √ötiles

- **Vercel CLI**: `npm i -g vercel`
- **VSCode Extension**: Vercel (oficial)
- **Testing**: Vitest para Edge Runtime
- **Type checking**: TypeScript strict mode

### Comunidad

- [Vercel Discord](https://vercel.com/discord)
- [GitHub Discussions](https://github.com/vercel/vercel/discussions)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/vercel)

---

## Glosario

| T√©rmino | Definici√≥n |
|---|---|
| **Edge Function** | Funci√≥n que se ejecuta en el edge m√°s cercano al usuario (V8 runtime) |
| **Serverless Function** | Funci√≥n tradicional con Node.js completo en regi√≥n √∫nica |
| **File-based routing** | Sistema donde la estructura de archivos determina las rutas API |
| **Cold start** | Tiempo de inicializaci√≥n cuando una funci√≥n no ha sido usada recientemente |
| **Fluid compute** | Sistema de Vercel para mantener functions warm y reducir cold starts |
| **Preview deployment** | Deploy autom√°tico de cada PR en URL √∫nica |
| **Edge Runtime** | Runtime ligero basado en V8 con Web Standard APIs |
| **waitUntil()** | API para ejecutar c√≥digo en background sin bloquear respuesta |
| **Route handler** | Funci√≥n exportada (GET, POST, etc.) en `route.ts` |
| **Runtime** | Entorno de ejecuci√≥n (edge o nodejs) |

---

**√öltima actualizaci√≥n**: 2025-10-06
**Autor**: claude-master
**Proyecto**: migue.ai - WhatsApp AI Assistant

